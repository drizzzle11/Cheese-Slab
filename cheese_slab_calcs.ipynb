{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Combine all load case Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder containing all Excel files\n",
    "cheeseslab_folder = 'C:\\\\Users\\\\rimjhims\\\\Walter P. Moore and Associates\\\\S17-24001-00 DB Texas Instruments LFAB2 - CheeseSlab\\\\Cheese Slab Export\\\\Forces'\n",
    "\n",
    "# List to store the Excel files\n",
    "cheeseslab_dataframes = []\n",
    "\n",
    "# Looping through all Excel files in Cheese Slab Export > Forces folder\n",
    "for file in os.listdir(cheeseslab_folder):\n",
    "    if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "        file_path = os.path.join(cheeseslab_folder, file)\n",
    "        # Read the Excel file and append to the list\n",
    "        cheeseslab_dataframes.append(pd.read_excel(file_path))\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "# CS == Cheese slab\n",
    "all_cs_loadcases = pd.concat(cheeseslab_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Parquet (data format)\n",
    "all_cs_loadcases.to_parquet('C:\\\\Users\\\\rimjhims\\\\Walter P. Moore and Associates\\\\S17-24001-00 DB Texas Instruments LFAB2 - CheeseSlab\\\\Cheese Slab Export\\\\all_cs_loadcases.parquet', engine = 'pyarrow', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24024000, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cs_loadcases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Extract minimum and maximum force values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique Element names\n",
    "all_elements = all_cs_loadcases['Elm'].unique()\n",
    "all_elements = all_elements.tolist()\n",
    "\n",
    "# Extract unique Load Cases\n",
    "all_loadcases = all_cs_loadcases['LoadCase'].unique()\n",
    "all_loadcases = all_loadcases.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_loadcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list to store rows as dictionaries\n",
    "result_rows = []\n",
    "\n",
    "# Loop through elements in all_elements\n",
    "for element in all_elements:\n",
    "\n",
    "    for load_case in all_loadcases:\n",
    "        # Extract element rows\n",
    "        relevant_rows = all_cs_loadcases[(all_cs_loadcases['Elm'] == element) & (all_cs_loadcases['LoadCase'] == load_case)]\n",
    "\n",
    "        # Collect min and max values for each column\n",
    "        result_row = {\n",
    "            'Elm': element,\n",
    "            'LoadCase': load_case,\n",
    "            'min_P': relevant_rows['P'].min(),\n",
    "            'max_P': relevant_rows['P'].max(),\n",
    "            'min_V2': relevant_rows['V2'].min(),\n",
    "            'max_V2': relevant_rows['V2'].max(),\n",
    "            'min_V3': relevant_rows['V3'].min(),\n",
    "            'max_V3': relevant_rows['V3'].max(),\n",
    "            'min_T': relevant_rows['T'].min(),\n",
    "            'max_T': relevant_rows['T'].max(),\n",
    "            'min_M2': relevant_rows['M2'].min(),\n",
    "            'max_M2': relevant_rows['M2'].max(),\n",
    "            'min_M3': relevant_rows['M3'].min(),\n",
    "            'max_M3': relevant_rows['M3'].max(),\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list\n",
    "        result_rows.append(result_row)\n",
    "\n",
    "# Create the result DataFrame\n",
    "result_df = pd.DataFrame(result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143000, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Extract all frames/points from Frame combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Frame combined file to DataFrame\n",
    "\n",
    "all_frame_path = 'C:\\\\Users\\\\rimjhims\\\\Walter P. Moore and Associates\\\\S17-24001-00 DB Texas Instruments LFAB2 - CheeseSlab\\\\Cheese Slab Export\\\\Location\\\\FRAME - Combined.xlsx'\n",
    "required_cols = ['Frame', 'CentroidX', 'CentroidY']\n",
    "\n",
    "frames = pd.read_excel(all_frame_path, usecols = required_cols)\n",
    "frames = frames.rename(columns = {'Frame' : 'Elm'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Merge result_df and frames @ 'Elm' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging frames and result_df\n",
    "all_elements_df = pd.merge(result_df, frames, on = 'Elm', how = 'left')\n",
    "\n",
    "# Reduce demicals point to a hundredth\n",
    "cols_to_reduce = ['min_P', 'max_P', 'min_V2', 'max_V2', 'min_V3', 'max_V3', 'min_T', 'max_T', 'min_M2', 'max_M2', 'min_M3', 'max_M3']\n",
    "\n",
    "# Reduce decimal points to hundredth place\n",
    "all_elements_df[cols_to_reduce] = all_elements_df[cols_to_reduce].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Pickling all_elements_df as Parquet/CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Parquet (data format)\n",
    "all_elements_df.to_parquet('C:\\\\Users\\\\rimjhims\\\\Walter P. Moore and Associates\\\\S17-24001-00 DB Texas Instruments LFAB2 - CheeseSlab\\\\Cheese Slab Export\\\\all_elements.parquet', engine = 'pyarrow', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to CSV (data format)\n",
    "all_elements_df.to_csv('C:\\\\Users\\\\rimjhims\\\\Walter P. Moore and Associates\\\\S17-24001-00 DB Texas Instruments LFAB2 - CheeseSlab\\\\Cheese Slab Export\\\\all_elements.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheese_slab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
